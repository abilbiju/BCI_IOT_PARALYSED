# BCI Motor Imagery Classification Configuration
# Phase 1: Core BCI Application (Intent Layer)

# EEG Data Parameters
eeg:
  sampling_rate: 256 # Hz - Common for BCI Competition IV
  channels: 59 # Total channels in dataset
  motor_imagery_channels: [
      7,
      9,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
    ] # C3, Cz, C4 and surrounding channels
  epoch_length: 1.0 # seconds - time window for classification
  overlap: 0.0 # seconds - overlap between epochs

# Signal Preprocessing Parameters
preprocessing:
  # Bandpass filter for motor imagery (mu and beta rhythms)
  bandpass:
    low_freq: 4.0 # Hz - Lower bound
    high_freq: 30.0 # Hz - Upper bound
    filter_order: 4 # Butterworth filter order

  # Reference method
  reference: "CAR" # Common Average Reference

  # Normalization
  normalization: "zscore" # z-score normalization

  # Artifact removal
  artifact_threshold: 100.0 # microvolts - threshold for artifact rejection

# EEGNet Model Parameters
model:
  # Architecture parameters
  nb_classes: 2 # Number of motor imagery classes (left vs right hand)
  chans: 35 # Number of channels to use (motor imagery channels)
  samples: 256 # Samples per epoch (1 second at 256 Hz)

  # EEGNet specific parameters
  dropoutRate: 0.5
  kernLength: 32 # Kernel size for temporal convolution
  F1: 8 # Number of temporal filters
  D: 2 # Depth multiplier (spatial filters per temporal filter)
  F2: 16 # Number of pointwise filters (F1 * D)
  norm_rate: 0.25 # Dropout rate for BatchNorm
  dropoutType: "Dropout" # Can be "Dropout" or "SpatialDropout2D"

# Training Parameters
training:
  batch_size: 16
  epochs: 300
  learning_rate: 0.001
  validation_split: 0.2
  early_stopping:
    patience: 50
    restore_best_weights: true

  # Data augmentation
  augmentation:
    enabled: true
    noise_std: 0.01 # Standard deviation for Gaussian noise
    time_shift_range: 10 # Maximum samples to shift in time

# Command Mapping (Motor Imagery Classes to IoT Commands)
commands:
  # Class index to command string mapping
  class_mapping:
    0: "TURN_LEFT" # Left hand motor imagery
    1: "TURN_RIGHT" # Right hand motor imagery

  # Extended command set for future expansion
  extended_commands:
    0: "FAN_OFF"
    1: "FAN_ON"
    2: "LIGHT_OFF"
    3: "LIGHT_ON"
    4: "MOVE_FORWARD"
    5: "MOVE_BACKWARD"
    6: "TURN_LEFT"
    7: "TURN_RIGHT"

# API Configuration
api:
  host: "localhost"
  port: 5000
  debug: true

  # Endpoints
  endpoints:
    classify: "/classify"
    status: "/status"
    model_info: "/model_info"

# File Paths
paths:
  data_file: "bci_preprocessed_data.npz"
  model_save_path: "models/"
  model_filename: "eegnet_motor_imagery.keras"
  logs_path: "logs/"

# Simulation Parameters
simulation:
  chunk_size: 256 # Samples per chunk (1 second)
  stream_delay: 0.1 # Seconds between chunks
  noise_level: 0.05 # Amplitude of simulated noise

# Logging Configuration
logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  save_to_file: true
  log_filename: "bci_application.log"
